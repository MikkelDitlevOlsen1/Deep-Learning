{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231f97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "from torch.nn.functional import one_hot\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36794c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change current directory up to parent, only run 1 time!\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46c42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads data from clean_data \n",
    "#path need to be set to the clean_data folder\n",
    "def load_data(test=False,Print=False,path=f'{os.path.abspath(os.curdir)}/data/carseg_data/clean_data',nr_img=1498):\n",
    "    train_data_input=[]\n",
    "    train_data_target=[]\n",
    "    \n",
    "    for n in range(nr_img):\n",
    "        n1=n\n",
    "        if test:\n",
    "            n1=f'{n}_a'\n",
    "        try:\n",
    "            test1=np.load(f'{path}/{n1}.npy')\n",
    "            \n",
    "            inputs=torch.from_numpy(test1[:3])\n",
    "            train_data_input.append(inputs)\n",
    "            \n",
    "            target=torch.from_numpy(test1[3])\n",
    "            target= torch.unsqueeze(target,0)\n",
    "            train_data_target.append(target)\n",
    "        except:\n",
    "            if Print:\n",
    "                print(f'fil nr {n} mangeler')\n",
    "    return [train_data_input,train_data_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc7d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=f'{os.path.abspath(os.curdir)}/data/carseg_data/clean_data'\n",
    "test1=np.load(f'{path}/{0}.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb8fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(test1[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b254dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((test1[3]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg_3d.get_data() # 3D numpy array with 9 different values\n",
    "num_labels = len(np.unique(seg)) # 9\n",
    "seg = torch.tensor(seg).to(torch.int64)\n",
    "seg_hot = one_hot(seg, num_labels)\n",
    "print(seg_hot.shape, torch.unique(seg_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 0, 3])\n",
    "b = np.zeros((a.size, a.max()+1))\n",
    "b[np.arange(a.size),a] = 1\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d175720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test and train data\n",
    "test_data=load_data(test=True)\n",
    "train_data=load_data()\n",
    "\n",
    "#split op into x and y\n",
    "test_x, test_y = test_data[0], test_data[1]\n",
    "train_x, train_y = train_data[0], train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223489bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data:\n",
      "Number of img 99\n",
      "target sahpe torch.Size([1, 256, 256])\n",
      "input shape torch.Size([3, 256, 256])\n",
      "train_data:\n",
      "Number of img 1128\n",
      "target sahpe torch.Size([1, 256, 256])\n",
      "input shape torch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "#the form of data is:\n",
    "#data[0] is a list with all rgb img's as tensor\n",
    "#data[1] is a list with all targets as tensor  \n",
    "def Get_stats(data):\n",
    "    print(f'Number of img {len(data[0])}')\n",
    "    print(f'target sahpe {data[1][0].shape}')\n",
    "    print(f'input shape {data[0][0].shape}')\n",
    "    \n",
    "    \n",
    "#print some info about data structure\n",
    "print('test_data:')\n",
    "Get_stats(test_data)\n",
    "print('train_data:')\n",
    "Get_stats(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0457b8",
   "metadata": {},
   "source": [
    "# one hot encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b43c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(data):\n",
    "    for i,y in enumerate(data):\n",
    "        data[i]=onehot1(y)\n",
    "        \n",
    "\n",
    "test_y=onehot(test_y)\n",
    "train_y=onehot(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def autocrop(encoder_layer: torch.Tensor, decoder_layer: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Center-crops the encoder_layer to the size of the decoder_layer,\n",
    "    so that merging (concatenation) between levels/blocks is possible.\n",
    "    This is only necessary for input sizes != 2**n for 'same' padding and always required for 'valid' padding.\n",
    "    \"\"\"\n",
    "    if encoder_layer.shape[2:] != decoder_layer.shape[2:]:\n",
    "        ds = encoder_layer.shape[2:]\n",
    "        es = decoder_layer.shape[2:]\n",
    "        assert ds[0] >= es[0]\n",
    "        assert ds[1] >= es[1]\n",
    "        if encoder_layer.dim() == 4:  # 2D\n",
    "            encoder_layer = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
    "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2)\n",
    "                            ]\n",
    "        elif encoder_layer.dim() == 5:  # 3D\n",
    "            assert ds[2] >= es[2]\n",
    "            encoder_layer = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
    "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2),\n",
    "                            ((ds[2] - es[2]) // 2):((ds[2] + es[2]) // 2),\n",
    "                            ]\n",
    "    return encoder_layer, decoder_layer\n",
    "\n",
    "\n",
    "def conv_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.Conv3d\n",
    "    elif dim == 2:\n",
    "        return nn.Conv2d\n",
    "\n",
    "\n",
    "def get_conv_layer(in_channels: int,\n",
    "                   out_channels: int,\n",
    "                   kernel_size: int = 3,\n",
    "                   stride: int = 1,\n",
    "                   padding: int = 1,\n",
    "                   bias: bool = True,\n",
    "                   dim: int = 2):\n",
    "    return conv_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                           bias=bias)\n",
    "\n",
    "\n",
    "def conv_transpose_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.ConvTranspose3d\n",
    "    elif dim == 2:\n",
    "        return nn.ConvTranspose2d\n",
    "\n",
    "\n",
    "def get_up_layer(in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 2,\n",
    "                 stride: int = 2,\n",
    "                 dim: int = 3,\n",
    "                 up_mode: str = 'transposed',\n",
    "                 ):\n",
    "    if up_mode == 'transposed':\n",
    "        return conv_transpose_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2.0, mode=up_mode)\n",
    "\n",
    "\n",
    "def maxpool_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.MaxPool3d\n",
    "    elif dim == 2:\n",
    "        return nn.MaxPool2d\n",
    "\n",
    "\n",
    "def get_maxpool_layer(kernel_size: int = 2,\n",
    "                      stride: int = 2,\n",
    "                      padding: int = 0,\n",
    "                      dim: int = 2):\n",
    "    return maxpool_layer(dim=dim)(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "\n",
    "def get_activation(activation: str):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n",
    "    elif activation == 'elu':\n",
    "        return nn.ELU()\n",
    "\n",
    "\n",
    "def get_normalization(normalization: str,\n",
    "                      num_channels: int,\n",
    "                      dim: int):\n",
    "    if normalization == 'batch':\n",
    "        if dim == 3:\n",
    "            return nn.BatchNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif normalization == 'instance':\n",
    "        if dim == 3:\n",
    "            return nn.InstanceNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.InstanceNorm2d(num_channels)\n",
    "    elif 'group' in normalization:\n",
    "        num_groups = int(normalization.partition('group')[-1])  # get the group size from string\n",
    "        return nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)\n",
    "\n",
    "\n",
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, layer_1, layer_2):\n",
    "        x = torch.cat((layer_1, layer_2), 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 MaxPool.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 pooling: bool = True,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: str = 2,\n",
    "                 conv_mode: str = 'same'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pooling = pooling\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "\n",
    "        # conv layers\n",
    "        self.conv1 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # pooling layer\n",
    "        if self.pooling:\n",
    "            self.pool = get_maxpool_layer(kernel_size=2, stride=2, padding=0, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # activation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "\n",
    "        before_pooling = y  # save the outputs before the pooling operation\n",
    "        if self.pooling:\n",
    "            y = self.pool(y)  # pooling\n",
    "        return y, before_pooling\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 UpConvolution/Upsample.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: int = 3,\n",
    "                 conv_mode: str = 'same',\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        # upconvolution/upsample layer\n",
    "        self.up = get_up_layer(self.in_channels, self.out_channels, kernel_size=2, stride=2, dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "        # conv layers\n",
    "        self.conv0 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv1 = get_conv_layer(2 * self.out_channels, self.out_channels, kernel_size=3, stride=1,\n",
    "                                    padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act0 = get_activation(self.activation)\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm0 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "        # concatenate layer\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "    def forward(self, encoder_layer, decoder_layer):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            encoder_layer: Tensor from the encoder pathway\n",
    "            decoder_layer: Tensor from the decoder pathway (to be up'd)\n",
    "        \"\"\"\n",
    "        up_layer = self.up(decoder_layer)  # up-convolution/up-sampling\n",
    "        cropped_encoder_layer, dec_layer = autocrop(encoder_layer, up_layer)  # cropping\n",
    "\n",
    "        if self.up_mode != 'transposed':\n",
    "            # We need to reduce the channel dimension with a conv layer\n",
    "            up_layer = self.conv0(up_layer)  # convolution 0\n",
    "        up_layer = self.act0(up_layer)  # activation 0\n",
    "        if self.normalization:\n",
    "            up_layer = self.norm0(up_layer)  # normalization 0\n",
    "\n",
    "        merged_layer = self.concat(up_layer, cropped_encoder_layer)  # concatenation\n",
    "        y = self.conv1(merged_layer)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # acivation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "        return y\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 3,\n",
    "                 out_channels: int = 8,\n",
    "                 n_blocks: int = 4,\n",
    "                 start_filters: int = 32,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = 'batch',\n",
    "                 conv_mode: str = 'same',\n",
    "                 dim: int = 2,\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_blocks = n_blocks\n",
    "        self.start_filters = start_filters\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.conv_mode = conv_mode\n",
    "        self.dim = dim\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        self.down_blocks = []\n",
    "        self.up_blocks = []\n",
    "\n",
    "        # create encoder path\n",
    "        for i in range(self.n_blocks):\n",
    "            num_filters_in = self.in_channels if i == 0 else num_filters_out\n",
    "            num_filters_out = self.start_filters * (2 ** i)\n",
    "            pooling = True if i < self.n_blocks - 1 else False\n",
    "\n",
    "            down_block = DownBlock(in_channels=num_filters_in,\n",
    "                                   out_channels=num_filters_out,\n",
    "                                   pooling=pooling,\n",
    "                                   activation=self.activation,\n",
    "                                   normalization=self.normalization,\n",
    "                                   conv_mode=self.conv_mode,\n",
    "                                   dim=self.dim)\n",
    "\n",
    "            self.down_blocks.append(down_block)\n",
    "\n",
    "        # create decoder path (requires only n_blocks-1 blocks)\n",
    "        for i in range(n_blocks - 1):\n",
    "            num_filters_in = num_filters_out\n",
    "            num_filters_out = num_filters_in // 2\n",
    "\n",
    "            up_block = UpBlock(in_channels=num_filters_in,\n",
    "                               out_channels=num_filters_out,\n",
    "                               activation=self.activation,\n",
    "                               normalization=self.normalization,\n",
    "                               conv_mode=self.conv_mode,\n",
    "                               dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "            self.up_blocks.append(up_block)\n",
    "\n",
    "        # final convolution\n",
    "        self.conv_final = get_conv_layer(num_filters_out, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                         bias=True, dim=self.dim)\n",
    "\n",
    "        # add the list of modules to current module\n",
    "        self.down_blocks = nn.ModuleList(self.down_blocks)\n",
    "        self.up_blocks = nn.ModuleList(self.up_blocks)\n",
    "\n",
    "        # initialize the weights\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.weight, **kwargs)  # weights\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.bias, **kwargs)  # bias\n",
    "\n",
    "    def initialize_parameters(self,\n",
    "                              method_weights=nn.init.xavier_uniform_,\n",
    "                              method_bias=nn.init.zeros_,\n",
    "                              kwargs_weights={},\n",
    "                              kwargs_bias={}\n",
    "                              ):\n",
    "        for module in self.modules():\n",
    "            self.weight_init(module, method_weights, **kwargs_weights)  # initialize weights\n",
    "            self.bias_init(module, method_bias, **kwargs_bias)  # initialize bias\n",
    "\n",
    "    def forward(self, x: torch.tensor):\n",
    "        encoder_output = []\n",
    "\n",
    "        # Encoder pathway\n",
    "        for module in self.down_blocks:\n",
    "            x, before_pooling = module(x)\n",
    "            encoder_output.append(before_pooling)\n",
    "\n",
    "        # Decoder pathway\n",
    "        for i, module in enumerate(self.up_blocks):\n",
    "            before_pool = encoder_output[-(i + 2)]\n",
    "            x = module(before_pool, x)\n",
    "\n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        attributes = {attr_key: self.__dict__[attr_key] for attr_key in self.__dict__.keys() if '_' not in attr_key[0] and 'training' not in attr_key}\n",
    "        d = {self.__class__.__name__: attributes}\n",
    "        return f'{d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3,\n",
    "             out_channels=9,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2)\n",
    "\n",
    "x = torch.randn(size=(4,3, 256, 256), dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "\n",
    "print(f'Out: {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66627258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary = summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 256\n",
    "def compute_max_depth(shape, max_depth=10, print_out=True):\n",
    "    shapes = []\n",
    "    shapes.append(shape)\n",
    "    for level in range(1, max_depth):\n",
    "        if shape % 2 ** level == 0 and shape / 2 ** level > 1:\n",
    "            shapes.append(shape / 2 ** level)\n",
    "            if print_out:\n",
    "                print(f'Level {level}: {shape / 2 ** level}')\n",
    "        else:\n",
    "            if print_out:\n",
    "                print(f'Max-level: {level - 1}')\n",
    "            break\n",
    "\n",
    "    return shapes\n",
    "\n",
    "\n",
    "out = compute_max_depth(shape, print_out=True, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3baf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset = None,\n",
    "                 lr_scheduler: torch.optim.lr_scheduler = None,\n",
    "                 epochs: int = 100,\n",
    "                 epoch: int = 0,\n",
    "                 notebook: bool = False\n",
    "                 ):\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.epoch = epoch\n",
    "        self.notebook = notebook\n",
    "\n",
    "        self.training_loss = []\n",
    "        self.validation_loss = []\n",
    "        self.learning_rate = []\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        progressbar = trange(self.epochs, desc='Progress')\n",
    "        for i in progressbar:\n",
    "            \"\"\"Epoch counter\"\"\"\n",
    "            self.epoch += 1  # epoch counter\n",
    "\n",
    "            \"\"\"Training block\"\"\"\n",
    "            self._train()\n",
    "\n",
    "            \"\"\"Validation block\"\"\"\n",
    "            if self.validation_DataLoader is not None:\n",
    "                self._validate()\n",
    "\n",
    "            \"\"\"Learning rate scheduler block\"\"\"\n",
    "            if self.lr_scheduler is not None:\n",
    "                if self.validation_DataLoader is not None and self.lr_scheduler.__class__.__name__ == 'ReduceLROnPlateau':\n",
    "                    self.lr_scheduler.batch(self.validation_loss[i])  # learning rate scheduler step with validation loss\n",
    "                else:\n",
    "                    self.lr_scheduler.batch()  # learning rate scheduler step\n",
    "        return self.training_loss, self.validation_loss, self.learning_rate\n",
    "\n",
    "    def _train(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        self.model.train()  # train mode\n",
    "        train_losses = []  # accumulate the losses here\n",
    "        batch_iter = tqdm(enumerate(self.training_DataLoader), 'Training', total=len(self.training_DataLoader),\n",
    "                          leave=False)\n",
    "\n",
    "        for i, (x, y) in batch_iter:\n",
    "            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "            self.optimizer.zero_grad()  # zerograd the parameters\n",
    "            out = self.model(input)  # one forward pass\n",
    "            loss = self.criterion(out, target)  # calculate loss\n",
    "            loss_value = loss.item()\n",
    "            train_losses.append(loss_value)\n",
    "            loss.backward()  # one backward pass\n",
    "            self.optimizer.step()  # update the parameters\n",
    "\n",
    "            batch_iter.set_description(f'Training: (loss {loss_value:.4f})')  # update progressbar\n",
    "\n",
    "        self.training_loss.append(np.mean(train_losses))\n",
    "        self.learning_rate.append(self.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        batch_iter.close()\n",
    "\n",
    "    def _validate(self):\n",
    "\n",
    "        if self.notebook:\n",
    "            from tqdm.notebook import tqdm, trange\n",
    "        else:\n",
    "            from tqdm import tqdm, trange\n",
    "\n",
    "        self.model.eval()  # evaluation mode\n",
    "        valid_losses = []  # accumulate the losses here\n",
    "        batch_iter = tqdm(enumerate(self.validation_DataLoader), 'Validation', total=len(self.validation_DataLoader),\n",
    "                          leave=False)\n",
    "\n",
    "        for i, (x, y) in batch_iter:\n",
    "            input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = self.model(input)\n",
    "                loss = self.criterion(out, target)\n",
    "                loss_value = loss.item()\n",
    "                valid_losses.append(loss_value)\n",
    "\n",
    "                batch_iter.set_description(f'Validation: (loss {loss_value:.4f})')\n",
    "\n",
    "        self.validation_loss.append(np.mean(valid_losses))\n",
    "\n",
    "        batch_iter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323189a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b437a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class batches(data.Dataset):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "\n",
    "        return np.array(batch_x),np.array(batch_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
